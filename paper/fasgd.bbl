\begin{thebibliography}{15}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2015)Bengio, Bacon, Pineau, and Precup]{Conditional}
Bengio, Emmanuel, Bacon, Pierre{-}Luc, Pineau, Joelle, and Precup, Doina.
\newblock Conditional computation in neural networks for faster models.
\newblock \emph{CoRR}, abs/1511.06297, 2015.
\newblock URL \url{http://arxiv.org/abs/1511.06297}.

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and Jauvin]{FirstASGD}
Bengio, Yoshua, Ducharme, Réjean, Vincent, Pascal, and Jauvin, Christian.
\newblock A neural probabilistic language model.
\newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 1137–1155,
  2003.

\bibitem[Bergstra et~al.(2010)Bergstra, Breuleux, Bastien, Lamblin, Pascanu,
  Desjardins, Turian, Warde-Farley, and Bengio]{Theano}
Bergstra, James, Breuleux, Olivier, Bastien, Fr{\'{e}}d{\'{e}}ric, Lamblin,
  Pascal, Pascanu, Razvan, Desjardins, Guillaume, Turian, Joseph, Warde-Farley,
  David, and Bengio, Yoshua.
\newblock Theano: a {CPU} and {GPU} math expression compiler.
\newblock \emph{Proceedings of the Python for Scientific Computing Conference
  ({SciPy})}, 2010.

\bibitem[Chan \& Lane(2014)Chan and Lane]{Rel}
Chan, William and Lane, Ian.
\newblock Distributed asynchronous optimization of convolutional neural
  networks.
\newblock In \emph{{INTERSPEECH} 2014, 15th Annual Conference of the
  International Speech Communication Association, Singapore, September 14-18,
  2014}, pp.\  1073--1077, 2014.
\newblock URL
  \url{http://www.isca-speech.org/archive/interspeech_2014/i14_1073.html}.

\bibitem[Chilimbi et~al.(2014)Chilimbi, Suzue, Apacible, and
  Kalyanaraman]{ADAM}
Chilimbi, Trishul, Suzue, Yutaka, Apacible, Johnson, and Kalyanaraman, Karthik.
\newblock Project adam: Building an efficient and scalable deep learning
  training system.
\newblock In \emph{11th USENIX Symposium on Operating Systems Design and
  Implementation (OSDI 14)}, pp.\  571--582, Broomfield, CO, October 2014.
  USENIX Association.
\newblock ISBN 978-1-931971-16-4.
\newblock URL
  \url{https://www.usenix.org/conference/osdi14/technical-sessions/presentation/chilimbi}.

\bibitem[Dean et~al.(2012)Dean, Corrado, Monga, Chen, Devin, Le, Mao, Ranzato,
  Senior, Tucker, Yang, and Ng]{Dean}
Dean, J., Corrado, G.S, Monga, R., Chen, K., Devin, M., Le, Q.V., Mao, M.Z.,
  Ranzato, M.A., Senior, A., Tucker, P., Yang, K., and Ng, A.~Y.
\newblock Large scale distributed deep networks.
\newblock In \emph{NIPS'2012}, 2012.

\bibitem[Graves(2013)]{Graves}
Graves, Alex.
\newblock Generating sequences with recurrent neural networks.
\newblock \emph{CoRR}, abs/1308.0850, 2013.
\newblock URL \url{http://arxiv.org/abs/1308.0850}.

\bibitem[Gupta et~al.(2015)Gupta, Zhang, and Milthorpe]{Tradeoffs}
Gupta, S., Zhang, W., and Milthorpe, J.
\newblock Model accuracy and runtime tradeoff in distributed deep learning.
\newblock \emph{CoRR}, abs/1509.04120, 2015.
\newblock URL \url{arXiv:1509.04210v2}.

\bibitem[Lavin \& Gray(2015)Lavin and Gray]{winograd}
Lavin, A. and Gray, S.
\newblock Fast algorithms for convolutional neural networks.
\newblock \emph{CoRR}, abs/1509.09308, 2015.
\newblock URL \url{http://arxiv.org/abs/1509.09308}.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{MNIST}
LeCun, Yann, Bottou, L\'eon, Bengio, Yoshua, and Haffner, Patrick.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 1998.

\bibitem[Lian et~al.(2015)Lian, Huang, Li, and Liu]{Lian}
Lian, Xiangru, Huang, Yijun, Li, Yuncheng, and Liu, Ji.
\newblock Asynchronous parallel stochastic gradient for nonconvex optimization.
\newblock In Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., and Garnett,
  R. (eds.), \emph{Advances in Neural Information Processing Systems 28}, pp.\
  2719--2727. Curran Associates, Inc., 2015.

\bibitem[Seide et~al.(2014)Seide, Fu, Droppo, Li, and Yu]{ONEBIT}
Seide, Frank, Fu, Hao, Droppo, Jasha, Li, Gang, and Yu, Dong.
\newblock 1-bit stochastic gradient descent and application to data-parallel
  distributed training of speech dnns.
\newblock In \emph{Interspeech 2014}, September 2014.
\newblock URL
  \url{http://research.microsoft.com/apps/pubs/default.aspx?id=230137}.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{RMSPROP}
Tieleman, Tijmen and Hinton, Geoffrey.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock \emph{Coursera: Neural Networks for Machine Learning}, 2012.

\bibitem[Wu et~al.(2015)Wu, Yan, Shan, Dang, and Sun]{Wu}
Wu, Ren, Yan, Shengen, Shan, Yi, Dang, Qingqing, and Sun, Gang.
\newblock Deep image: Scaling up image recognition.
\newblock \emph{CoRR}, abs/1501.02876, 2015.
\newblock URL \url{http://arxiv.org/abs/1501.02876}.

\bibitem[Zhang et~al.(2015)Zhang, Gupta, Lian, and Liu]{Suyog}
Zhang, Wei, Gupta, Suyog, Lian, Xiangru, and Liu, Ji.
\newblock Staleness-aware async-sgd for distributed deep learning.
\newblock \emph{arXiv preprint arXiv:1511.05950}, 2015.

\end{thebibliography}
